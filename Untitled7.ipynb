{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "What is a parameter?"
      ],
      "metadata": {
        "id": "4Lfh86nokI3o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "In machine learning, a parameter refers to a configuration variable that is internal to the model and whose value is estimated from the data. Parameters are learned from the training data during the training process, and they help the model make predictions"
      ],
      "metadata": {
        "id": "pWl07cYFkRkb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is correlation?\n",
        "What does negative correlation mean?"
      ],
      "metadata": {
        "id": "PPUj0DGGkhhW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Correlation is a statistical measure that describes the strength and direction of a relationship between two variables. It quantifies how changes in one variable are associated with changes in another. The correlation coefficient, typically denoted as\n",
        "𝑟\n",
        ", ranges from -1 to 1.\n",
        "\n",
        "Positive Correlation: When\n",
        "𝑟\n",
        ">\n",
        "0\n",
        ", it means that as one variable increases, the other variable also increases. For example, height and weight often have a positive correlation.\n",
        "\n",
        "Negative Correlation: When\n",
        "𝑟\n",
        "<\n",
        "0\n",
        ", it indicates that as one variable increases, the other variable decreases. For example, the number of hours spent watching TV and grades might have a negative correlation.\n",
        "\n",
        "No Correlation: When\n",
        "𝑟\n",
        "=\n",
        "0\n",
        ", it means there is no linear relationship between the variables."
      ],
      "metadata": {
        "id": "qJgKu_FxkwIo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define Machine Learning. What are the main components in Machine Learning?"
      ],
      "metadata": {
        "id": "CjoLta-Lk7Gz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Machine Learning (ML) is a subset of artificial intelligence (AI) that focuses on developing algorithms and statistical models that enable computers to perform specific tasks without explicit instructions. Instead, these systems learn from data, identifying patterns, making decisions, and improving over time. Essentially, machine learning algorithms build a model based on sample data, known as training data, to make predictions or decisions without being specifically programmed to perform the task.\n",
        "\n",
        "Main Components of Machine Learning\n",
        "Data:\n",
        "\n",
        "Training Data: The dataset used to train the model. It includes inputs and corresponding outputs.\n",
        "\n",
        "Testing Data: The dataset used to evaluate the performance of the trained model. It helps in assessing how well the model generalizes to new, unseen data.\n",
        "\n",
        "Features:\n",
        "\n",
        "Features: The individual measurable properties or characteristics of the data. Features are used as input to the machine learning model.\n",
        "\n",
        "Feature Engineering: The process of using domain knowledge to create features that help machine learning models perform better.\n",
        "\n",
        "Algorithms:\n",
        "\n",
        "Supervised Learning: Algorithms that learn from labeled data. Common algorithms include linear regression, decision trees, and support vector machines.\n",
        "\n",
        "Unsupervised Learning: Algorithms that learn from unlabeled data. Examples include k-means clustering and principal component analysis.\n",
        "\n",
        "Reinforcement Learning: Algorithms that learn by interacting with an environment and receiving feedback in the form of rewards or penalties.\n",
        "\n",
        "Models:\n",
        "\n",
        "Model: The mathematical representation of the relationship between input features and the output. It is what the algorithm produces after training.\n",
        "\n",
        "Model Training: The process of fitting the model to the training data.\n",
        "\n",
        "Model Evaluation: Assessing the model's performance using metrics such as accuracy, precision, recall, and F1 score.\n",
        "\n",
        "Training Process:\n",
        "\n",
        "Training: The phase where the model learns from the training data.\n",
        "\n",
        "Validation: Using a separate validation dataset to tune the model's hyperparameters and prevent overfitting.\n",
        "\n",
        "Testing: Evaluating the final model on the testing dataset to assess its performance.\n",
        "\n",
        "Hyperparameters:\n",
        "\n",
        "Hyperparameters: Configuration settings used to tune the learning process. Unlike parameters, hyperparameters are set before training and include learning rate, number of iterations, and batch size.\n",
        "\n",
        "Loss Function:\n",
        "\n",
        "Loss Function: A function that measures the difference between the predicted output and the actual output. The goal of the learning process is to minimize this loss.\n",
        "\n",
        "Optimization Algorithm:\n",
        "\n",
        "Optimization Algorithm: Algorithms like gradient descent used to adjust the parameters of the model to minimize the loss function.\n",
        "\n",
        "Deployment:\n",
        "\n",
        "Model Deployment: The process of making the trained model available for use in a production environment."
      ],
      "metadata": {
        "id": "vK8ii8vclCok"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How does loss value help in determining whether the model is good or not?"
      ],
      "metadata": {
        "id": "7VMGSW_TlYc2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "he loss value is a critical metric used to evaluate the performance of a machine learning model. It measures the difference between the model's predictions and the actual values. Here's how the loss value helps in determining whether the model is good or not:\n",
        "\n",
        "Understanding Loss Value\n",
        "Loss Function: This is a mathematical function that computes the loss, i.e., the error between the predicted value and the true value. Common loss functions include Mean Squared Error (MSE) for regression tasks and Cross-Entropy Loss for classification tasks."
      ],
      "metadata": {
        "id": "JzAYiGN5lqZP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What are continuous and categorical variables?"
      ],
      "metadata": {
        "id": "hNh6WfHvlwEf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Continuous Variables\n",
        "Continuous variables can take an infinite number of values within a given range. These values are measurable and can include decimals and fractions. Continuous variables are often associated with real numbers and are used to represent measurements or quantities.\n",
        "\n",
        "Examples:\n",
        "\n",
        "Height (e.g., 170.5 cm)\n",
        "\n",
        "Weight (e.g., 68.2 kg)\n",
        "\n",
        "Temperature (e.g., 36.6°C)\n",
        "\n",
        "Time (e.g., 3.45 hours)\n",
        "\n",
        "Distance (e.g., 10.5 kilometers)\n",
        "\n",
        "Categorical Variables\n",
        "Categorical variables, also known as qualitative variables, represent distinct categories or groups. These values are not measurable in a numerical sense but describe attributes or qualities. Categorical variables can be further classified into nominal and ordinal variables:\n",
        "\n",
        "Nominal Variables: Categories that do not have a specific order or ranking. Examples include gender (male, female), marital status (single, married), and eye color (blue, brown, green).\n",
        "\n",
        "Ordinal Variables: Categories that have a specific order or ranking. Examples include education level (high school, bachelor's, master's), customer satisfaction rating (poor, fair, good, excellent), and socioeconomic status (low, middle, high).\n",
        "\n",
        "Examples:\n",
        "\n",
        "Gender (e.g., male, female)\n",
        "\n",
        "Blood Type (e.g., A, B, AB, O)\n",
        "\n",
        "Color (e.g., red, blue, green)\n",
        "\n",
        "Type of Fruit (e.g., apple, banana, cherry)"
      ],
      "metadata": {
        "id": "bVxD1HVH_ZoI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do we handle categorical variables in Machine Learning? What are the common t\n",
        "echniques?"
      ],
      "metadata": {
        "id": "MW4IUIfZBkhE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Encoding:\n",
        "\n",
        "Assign unique numerical values to each category.\n",
        "\n",
        "One-Hot Encoding:\n",
        "\n",
        "Create binary columns for each category.\n",
        "\n",
        "Ordinal Encoding:\n",
        "\n",
        "Assign numerical values to categories based on their order.\n",
        "\n",
        "Binary Encoding:\n",
        "\n",
        "Convert categories into binary numbers and split those into separate columns.\n",
        "\n",
        "Frequency Encoding:\n",
        "\n",
        "Replace categories with their frequency of occurrence.\n",
        "\n",
        "Target Encoding:\n",
        "\n",
        "Replace categories with the mean of the target variable for that category.\n",
        "\n",
        "Hashing Encoding:\n",
        "\n",
        "Use a hash function to convert categories into numerical values."
      ],
      "metadata": {
        "id": "Na6UgFxyB2yB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What do you mean by training and testing a dataset?"
      ],
      "metadata": {
        "id": "sDI9-lcuB56r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training and Testing a Dataset\n",
        "Training Dataset\n",
        "Purpose: Used to train the machine learning model.\n",
        "\n",
        "Function: The model learns patterns, relationships, and underlying structure from this data.\n",
        "\n",
        "Process: The algorithm adjusts its parameters based on this data to minimize error and improve accuracy.\n",
        "\n",
        "Testing Dataset\n",
        "Purpose: Used to evaluate the performance of the trained model.\n",
        "\n",
        "Function: The model makes predictions on this unseen data to test its generalization ability.\n",
        "\n",
        "Process: The performance metrics (e.g., accuracy, precision, recall) are calculated based on the model's predictions compared to the actual outcomes."
      ],
      "metadata": {
        "id": "WW3XKhsNCCsu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is sklearn.preprocessing?"
      ],
      "metadata": {
        "id": "Qr_gQ9KxCG_j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sklearn.preprocessing is a module in the scikit-learn library that provides various functions and utilities for preprocessing data. Preprocessing is an essential step in the machine learning pipeline to transform raw data into a format suitable for modeling."
      ],
      "metadata": {
        "id": "OjR5I40iCQWy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a Test set?"
      ],
      "metadata": {
        "id": "Pef17_14CVPc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is a Test set?\n",
        "A test set is a subset of your dataset that is used to evaluate the performance of a trained machine learning model. It contains data that the model has not seen during training, allowing you to assess how well the model generalizes to new, unseen data.\n",
        "\n",
        "Key Points About a Test Set:\n",
        "Purpose:\n",
        "\n",
        "To provide an unbiased evaluation of the final model's performance.\n",
        "\n",
        "To simulate how the model will perform in a real-world scenario with new data.\n",
        "\n",
        "Usage:\n",
        "\n",
        "After training the model on the training set, the test set is used to test the model's predictions.\n",
        "\n",
        "Performance metrics such as accuracy, precision, recall, F1 score, and others are calculated based on the test set results.\n",
        "\n",
        "Composition:\n",
        "\n",
        "The test set should be representative of the same distribution as the training set to provide a valid assessment.\n",
        "\n",
        "It is usually a random subset, separate from the training and validation sets.\n",
        "\n",
        "Best Practices:\n",
        "\n",
        "The test set should remain untouched during the training and hyperparameter tuning processes to ensure an unbiased evaluation.\n",
        "\n",
        "It's typically a small portion of the overall dataset, often around 20-30% of the total data."
      ],
      "metadata": {
        "id": "a-l47TrMCivz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do we split data for model fitting (training and testing) in Python?\n",
        "How do you approach a Machine Learning problem?"
      ],
      "metadata": {
        "id": "GQ564ZymCnTZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Approaching a Machine Learning Problem\n",
        "Approaching a machine learning problem systematically ensures a better chance of developing an effective and accurate model. Here's a general approach:\n",
        "\n",
        "Define the Problem:\n",
        "\n",
        "Clearly understand the problem you're trying to solve.\n",
        "\n",
        "Identify the objective and what you want to achieve with the model.\n",
        "\n",
        "Collect and Understand the Data:\n",
        "\n",
        "Gather relevant data from available sources.\n",
        "\n",
        "Perform exploratory data analysis (EDA) to understand the data distribution, identify patterns, and detect anomalies.\n",
        "\n",
        "Preprocess the Data:\n",
        "\n",
        "Handle Missing Values: Impute or remove missing data.\n",
        "\n",
        "Convert Categorical Variables: Use techniques like Label Encoding or One-Hot Encoding.\n",
        "\n",
        "Scale/Normalize Features: Ensure features are on a similar scale for algorithms sensitive to feature scaling.\n",
        "\n",
        "Feature Engineering:\n",
        "\n",
        "Create New Features: Derive new features from existing ones if they add value.\n",
        "\n",
        "Select Features: Identify and select relevant features that contribute to the model's performance.\n",
        "\n",
        "Split the Data:\n",
        "\n",
        "Split the data into training, validation, and test sets to ensure unbiased evaluation of the model.\n",
        "\n",
        "Choose and Train the Model:\n",
        "\n",
        "Select appropriate machine learning algorithms.\n",
        "\n",
        "Train the model using the training data.\n",
        "\n",
        "Evaluate the Model:\n",
        "\n",
        "Use the validation set to tune hyperparameters and improve the model.\n",
        "\n",
        "Evaluate the final model on the test set to assess its performance.\n",
        "\n",
        "Optimize and Improve the Model:\n",
        "\n",
        "Hyperparameter Tuning: Use techniques like Grid Search or Random Search for tuning.\n",
        "\n",
        "Ensemble Methods: Combine multiple models to improve accuracy.\n",
        "\n",
        "Deploy the Model:\n",
        "\n",
        "Integrate the trained model into a production environment for real-world use.\n",
        "\n",
        "Monitor and Maintain the Model:\n",
        "\n",
        "Continuously monitor the model's performance.\n",
        "\n",
        "Update and retrain the model as needed to adapt to new data or changing conditions."
      ],
      "metadata": {
        "id": "e9Aph41nC1gY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Why do we have to perform EDA before fitting a model to the data?"
      ],
      "metadata": {
        "id": "j_aeC8FYC5mR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Performing Exploratory Data Analysis (EDA) before fitting a model to the data is crucial for several reasons:\n",
        "\n",
        "1. Understand Data Structure and Distribution:\n",
        "Gain Insights: EDA helps you understand the underlying structure, patterns, and distribution of the data.\n",
        "\n",
        "Detect Outliers: Identify outliers that may skew your results or indicate data entry errors.\n",
        "\n",
        "2. Identify Data Quality Issues:\n",
        "Missing Values: Detect and handle missing values appropriately.\n",
        "\n",
        "Data Types: Ensure that all data types are correctly formatted for analysis.\n",
        "\n",
        "3. Uncover Relationships and Patterns:\n",
        "Correlations: Identify relationships between variables that can inform feature selection and engineering.\n",
        "\n",
        "Trend Analysis: Observe trends and patterns that can influence the model's predictions.\n",
        "\n",
        "4. Feature Selection and Engineering:\n",
        "Relevant Features: Determine which features are most relevant to the target variable.\n",
        "\n",
        "New Features: Create new features that may enhance the model's performance.\n",
        "\n",
        "5. Inform Modeling Decisions:\n",
        "Model Choice: Select appropriate modeling techniques based on the data's characteristics.\n",
        "\n",
        "Preprocessing Needs: Decide on necessary preprocessing steps such as scaling, encoding, and normalization.\n",
        "\n",
        "6. Visualize Data:\n",
        "Graphical Analysis: Use visualizations to gain a clearer understanding of data distributions, relationships, and potential issues."
      ],
      "metadata": {
        "id": "gQ9nvLlLDI5t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is correlation?"
      ],
      "metadata": {
        "id": "LULsihNsDRRT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "orrelation is a statistical measure that describes the extent to which two variables are related to each other. It indicates the strength and direction of a linear relationship between variables.\n",
        "\n",
        "Key Points About Correlation:\n",
        "Direction:\n",
        "\n",
        "Positive Correlation: Both variables move in the same direction. As one increases, the other also increases, and as one decreases, the other also decreases.\n",
        "\n",
        "Negative Correlation: The variables move in opposite directions. As one increases, the other decreases.\n",
        "\n",
        "Strength:\n",
        "\n",
        "The strength of the correlation is represented by the correlation coefficient (usually denoted as\n",
        "𝑟\n",
        ").\n",
        "\n",
        "The value of\n",
        "𝑟\n",
        " ranges from -1 to 1.\n",
        "\n",
        "𝑟\n",
        "=\n",
        "1\n",
        ": Perfect positive correlation.\n",
        "\n",
        "𝑟\n",
        "=\n",
        "−\n",
        "1\n",
        ": Perfect negative correlation.\n",
        "\n",
        "𝑟\n",
        "=\n",
        "0\n",
        ": No correlation (the variables are not related).\n",
        "\n",
        "Calculating Correlation:\n",
        "The most common method to calculate correlation is the Pearson correlation coefficient, which measures the linear relationship between two continuous variables."
      ],
      "metadata": {
        "id": "Cl69NM2MDbE2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does negative correlation mean?"
      ],
      "metadata": {
        "id": "dG9-7yIbDebn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative correlation describes a relationship between two variables in which one variable increases while the other decreases. This inverse relationship is characterized by a correlation coefficient (r) that ranges from -1 to 0.\n",
        "\n",
        "Key Points About Negative Correlation:\n",
        "Direction:\n",
        "\n",
        "As one variable increases, the other variable decreases.\n",
        "\n",
        "Conversely, as one variable decreases, the other variable increases.\n",
        "\n",
        "Strength:\n",
        "\n",
        "The closer the correlation coefficient (r) is to -1, the stronger the negative correlation.\n",
        "\n",
        "If\n",
        "𝑟\n",
        "=\n",
        "−\n",
        "1\n",
        ", it indicates a perfect negative correlation.\n",
        "\n",
        "If\n",
        "𝑟\n",
        " is closer to 0, the negative correlation is weaker."
      ],
      "metadata": {
        "id": "ZdmQHm5vDkEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does negative correlation mean?"
      ],
      "metadata": {
        "id": "ONJIuoTxDov0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative correlation refers to a relationship between two variables in which one variable increases as the other decreases. This inverse relationship is characterized by a correlation coefficient (r) that ranges from -1 to 0.\n",
        "\n",
        "Key Points About Negative Correlation:\n",
        "Direction:\n",
        "\n",
        "As one variable increases, the other variable decreases.\n",
        "\n",
        "Conversely, as one variable decreases, the other variable increases.\n",
        "\n",
        "Strength:\n",
        "\n",
        "The closer the correlation coefficient (r) is to -1, the stronger the negative correlation.\n",
        "\n",
        "If\n",
        "𝑟\n",
        "=\n",
        "−\n",
        "1\n",
        ", it indicates a perfect negative correlation.\n",
        "\n",
        "If\n",
        "𝑟\n",
        " is closer to 0, the negative correlation is weaker."
      ],
      "metadata": {
        "id": "cIRxWGuADyC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "How can you find correlation between variables in Python?"
      ],
      "metadata": {
        "id": "hMRLf7miD03w"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualize the correlation matrix using a heatmap sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm') plt.show()"
      ],
      "metadata": {
        "id": "iHml9iWtEuWe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is causation? Explain difference between correlation and causation with an example."
      ],
      "metadata": {
        "id": "F6Xjxh0CEx-M"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Causation\n",
        "Causation refers to a relationship between two events or variables where one event (the cause) directly leads to the occurrence of another event (the effect). In other words, changes in one variable bring about changes in another variable.\n",
        "\n",
        "Correlation vs. Causation\n",
        "Correlation indicates a statistical relationship between two variables, meaning they tend to move together, but it does not imply that one causes the other. Causation, on the other hand, implies that one event is the direct result of another.\n",
        "\n",
        "Example\n",
        "Correlation: Ice Cream Sales and Drowning Incidents\n",
        "\n",
        "There is a positive correlation between ice cream sales and drowning incidents.\n",
        "\n",
        "When ice cream sales increase, drowning incidents also increase.\n",
        "\n",
        "This does not mean that eating ice cream causes drowning. Instead, a lurking variable, like hot weather, is responsible for both increasing ice cream sales and the likelihood of swimming (which can lead to drowning incidents).\n",
        "\n",
        "Causation: Smoking and Lung Cancer\n",
        "\n",
        "Smoking is causally linked to lung cancer.\n",
        "\n",
        "Studies have shown that smoking causes changes in lung tissue, leading to cancer.\n",
        "\n",
        "Therefore, an increase in smoking directly causes an increase in lung cancer cases.\n",
        "\n",
        "Summary\n",
        "Correlation: Indicates a relationship between two variables but does not prove that one causes the other.\n",
        "\n",
        "Causation: Indicates that one variable directly affects another.\n",
        "\n",
        "Understanding the difference between correlation and causation is crucial for making accurate inferences in research and data analysis.\n",
        "\n"
      ],
      "metadata": {
        "id": "QbaSJfINEzLO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is an Optimizer? What are different types of optimizers? Explain each with an example."
      ],
      "metadata": {
        "id": "QjcgHUqoFJQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adagrad, Nadam\n",
        "\n",
        "# Example model\n",
        "model = Sequential([\n",
        "    Dense(64, input_shape=(10,), activation='relu'),\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n",
        "\n",
        "# Different optimizers\n",
        "optimizers = {\n",
        "    \"SGD\": SGD(learning_rate=0.01),\n",
        "    \"Momentum\": SGD(learning_rate=0.01, momentum=0.9),\n",
        "    \"Adagrad\": Adagrad(learning_rate=0.01),\n",
        "    \"RMSprop\": RMSprop(learning_rate=0.001),\n",
        "    \"Adam\": Adam(learning_rate=0.001),\n",
        "    \"Nadam\": Nadam(learning_rate=0.001)\n",
        "}\n",
        "\n",
        "# Compile models with different optimizers\n",
        "for name, optimizer in optimizers.items():\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    print(f\"Compiled with {name} optimizer\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-5Lox4x4Fim2",
        "outputId": "2b46ae23-4024-46d8-b380-80f2b39cfd4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiled with SGD optimizer\n",
            "Compiled with Momentum optimizer\n",
            "Compiled with Adagrad optimizer\n",
            "Compiled with RMSprop optimizer\n",
            "Compiled with Adam optimizer\n",
            "Compiled with Nadam optimizer\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What is sklearn.linear_model ?"
      ],
      "metadata": {
        "id": "DLa7Y1RzFviV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "sklearn.linear_model is a module within the scikit-learn library that provides various linear models for regression and classification tasks. These models are based on linear relationships between the input features and the target variable"
      ],
      "metadata": {
        "id": "6VHW1cvqGVH_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "What does model.fit() do? What arguments must be given?"
      ],
      "metadata": {
        "id": "iSkcsLoVGYS4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model.fit() function is a key method in scikit-learn and other machine learning libraries used to train a model. It fits the model to the provided data, adjusting the parameters to minimize the loss function and improve accuracy.\n",
        "\n",
        "What model.fit() Does:\n",
        "Training: It trains the model on the input data and the corresponding target values.\n",
        "\n",
        "Parameter Adjustment: It adjusts the model parameters (weights and biases) to find the optimal solution that minimizes the loss function.\n",
        "\n",
        "Required Arguments for model.fit():\n",
        "X:\n",
        "\n",
        "The training data (features).\n",
        "\n",
        "It should be in the form of an array-like structure, such as a NumPy array or a pandas DataFrame.\n",
        "\n",
        "y:\n",
        "\n",
        "The target values (labels).\n",
        "\n",
        "It should also be in the form of an array-like structure.\n",
        "\n",
        "Example:\n",
        "Here is a basic example using LinearRegression from sklearn.linear_model:\n",
        "\n",
        "python\n",
        "from sklearn.linear_model import LinearRegression\n",
        "import numpy as np\n",
        "\n",
        "# Sample data\n",
        "X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
        "y = np.dot(X, np.array([1, 2])) + 3\n",
        "\n",
        "# Initialize the model\n",
        "model = LinearRegression()\n",
        "\n",
        "# Fit the model to the data\n",
        "model.fit(X, y)"
      ],
      "metadata": {
        "id": "88ZekxCsGmA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explain data encoding?"
      ],
      "metadata": {
        "id": "iKeUMwztGq0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data encoding is the process of converting categorical data into numerical format so that machine learning algorithms can process it. This is a crucial step in data preprocessing because many algorithms require numerical input"
      ],
      "metadata": {
        "id": "ZPfjvyuuG-Hc"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hw-D0O6AF5vN"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}